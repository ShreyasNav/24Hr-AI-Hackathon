{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\nimport numpy as np\n\nfile_path = '/path/to/ohlcv_data.csv'  # Update this to the actual path\ndf = pd.read_csv(file_path)\n\n# Load your CSV file for sentiment data\nsentiment_file_path = '/path/to/sentiment_data.csv'  # Update this to the actual path\nsentiment_df = pd.read_csv(sentiment_file_path)\n\n# Merge OHLCV and sentiment data on a common key (e.g., date)\ndf = pd.merge(df, sentiment_df, on='date')\n\n# Define the features and target (closing price)\nfeatures = ['open_x', 'high_x', 'low_x', 'volumefrom_x', 'volumeto_x', 'sentiment_positive', 'sentiment_negative', 'sentiment_neutral']\ntarget = ['close_x']\n\n# Preprocess the data\nscaler = MinMaxScaler()\ndf_scaled = scaler.fit_transform(df[features + target])\n\n# Define a custom dataset for time series prediction\nclass StockDataset(Dataset):\n    def __init__(self, data, seq_length):\n        self.data = data\n        self.seq_length = seq_length\n        \n    def __len__(self):\n        return len(self.data) - self.seq_length\n    \n    def __getitem__(self, idx):\n        seq_x = self.data[idx:idx + self.seq_length, :-1]  # All features except the target (closing price)\n        seq_y = self.data[idx + self.seq_length, -1]  # The target (closing price)\n        return torch.FloatTensor(seq_x), torch.FloatTensor([seq_y])\n\nseq_length = 10  \n\n# Use all rows for training\ntrain_data = df_scaled  \ndataset = StockDataset(train_data, seq_length)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# Define the Transformer model\nclass StockTransformer(nn.Module):\n    def __init__(self, input_size, d_model, nhead, num_layers, seq_length):\n        super(StockTransformer, self).__init__()\n        self.embedding = nn.Linear(input_size, d_model)\n        self.pos_encoder = nn.Parameter(torch.zeros(seq_length, 1, d_model))  \n        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_layers)\n        self.fc_out = nn.Linear(d_model, 1)\n    \n    def forward(self, x):\n        # x shape: \n        x = self.embedding(x) \n        x = x.permute(1, 0, 2)  \n        x = x + self.pos_encoder \n        x = self.transformer(x, x)\n        out = self.fc_out(x[-1, :, :])  \n        return out\n\n# Initialize model, loss function, and optimizer\ninput_size = len(features)  # Number of input features (OHLCV + sentiments)\nd_model = 64\nnhead = 8\nnum_layers = 4\n\nmodel = StockTransformer(input_size, d_model, nhead, num_layers, seq_length)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# Function to train the model\ndef train_model(model, dataloader, epochs):\n    model.train()\n    train_losses = []\n\n    for epoch in range(epochs):\n        epoch_loss = 0\n        \n        for batch_x, batch_y in dataloader:\n            optimizer.zero_grad()\n            output = model(batch_x)\n            loss = criterion(output, batch_y)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n\n        epoch_loss /= len(dataloader)\n        train_losses.append(epoch_loss)\n        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}')\n\n    return train_losses\n\nepochs = 30\ntrain_losses = train_model(model, dataloader, epochs)\n\n\ndef predict_next_10_days(model, last_sequence, future_sentiment_data, n_predictions=10):\n    model.eval()\n    predictions = []\n    current_sequence = last_sequence.copy()\n    \n    with torch.no_grad():\n        for i in range(n_predictions):\n             \n            current_sequence[:, -3:] = future_sentiment_data[i]  \n            \n            current_sequence_tensor = torch.FloatTensor(current_sequence).unsqueeze(0)\n            \n        \n            predicted_price = model(current_sequence_tensor).squeeze().numpy()\n            predictions.append(predicted_price)\n            \n            new_day = np.zeros(current_sequence.shape[1])\n            new_day[-1] = predicted_price  \n            current_sequence = np.vstack([current_sequence[1:], new_day])\n    \n    return np.array(predictions)\n\nlast_10_days_data = df_scaled[-seq_length:, :-1]  \n\n\nfuture_sentiment_data = sentiment_df[-10:][['sentiment_positive', 'sentiment_negative', 'sentiment_neutral']].values\n\n\npredicted_prices = predict_next_10_days(model, last_10_days_data, future_sentiment_data, n_predictions=10)\n\n\ndummy_array = np.zeros((predicted_prices.shape[0], len(features) + 1))  \ndummy_array[:, -1] = predicted_prices  \n\npredicted_prices_rescaled = scaler.inverse_transform(dummy_array)[:, -1]  # Get the closing prices only\n\npredicted_df = pd.DataFrame({'day': np.arange(1, 11), 'predicted_closing_price': predicted_prices_rescaled})\npredicted_df.to_csv('predicted_prices.csv', index=False)\n\nplt.figure(figsize=(10, 6))\ndays = np.arange(len(df_scaled) + 1, len(df_scaled) + 11)\nplt.plot(days, predicted_prices_rescaled, label='Predicted')\nplt.xlabel('Days')\nplt.ylabel('Closing Price')\nplt.title('Predicted Stock Prices for Next 10 Days')\nplt.legend()\nplt.show()\n\nprint(predicted_df)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}